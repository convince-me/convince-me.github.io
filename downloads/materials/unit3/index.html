<html><head><title>Convince Me Unit 3: Using Convince Me </title><meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"><link rel="stylesheet" href="../../cm.css" type="text/css"></head><body bgcolor=white><center><h1>Convince Me Unit 3: Using Convince Me</h1></center><br><h2>What is Convince Me?</h2><p>Convince Me is a computer program to help you think about your own reasoning.  The program lets you type in short, sentence-like statements: things you believe and   are sure of, and beliefs/things you're not so sure of.  Then you can tell the computer   which ideas explain and contradict the other ideas (see Figure 1).  </p><h2>So what? Why do I need a computer for that?</h2><p> You don't.  But just as explaining something to another person can help you  understand something, entering an argument into Convince Me  can help you clarify   your own beliefs. Also, just as people will often tell you what they agree and disagree   with in your argument, Convince Me  will, in a similar way, tell you which statements  your argument helps to affirm or reject and which ones it leaves neutral, from  the computer's point of view.  </p><h2>How does the computer know what to believe?</h2><p> It doesn't, except for what you tell it. When you put a statement in the  computer, you'll be asked whether it is a piece of evidence or a hypothesis.   Decide carefully, since the computer gives more weight to all pieces of evidence   and then tries to figure out which hypotheses and evidence "hang together" best.  <b>The computer doesn't understand the meanings of the statements that you type in</b>.  It just tries to figure out which statements to believe on the basis of your  argument––by what you tell it about what contradicts what, and what explains  what.  Convince Me uses a computer program called ECHO to do this. </p><br><p align="center"><img width=504 height=472 src="fig1a.gif"></p><p align="center"><img width=490 height=436 src="fig1b.gif"></p><p align="center"><b>Figure 1</b>. Adding a belief about the speeds at which water   of different initial temperatures freezes (bottom) in response to Convince Me's   feedback (top).</p><br><h2>What is "ECHO"?</h2><p>ECHO is a computer model based on a theory called the "Theory of Explanatory   Coherence" (TEC). TEC attempts to account for how people decide the plausibility   of beliefs asserted in an explanation or argument.  The theory is based on a  few "hall of fame" <b>principles of reasoning</b>, such as: </p><ol> <li>The believability of an idea generally increases with increasing simplicity.      In other words, making lots of (that is, joint) assumptions is often counterproductive,    compared to making fewer assumptions.  </li> <li>People tend to believe statements when there is more evidence to support them.</li> <li>We are more likely to believe something that doesn't conflict or compete with other    things we strongly believe.</li></ol><p>To learn more about TEC's principles, see the <a href="#appendix">Appendix</a>.</p><p>ECHO is a computer model based on TEC. In ECHO, arguments are represented as <b>networks</b>   of <b>nodes</b> (like knots in a net).  A hypothesis or piece of evidence is represented by   a node, and explanatory or contradictory relations are represented by <b>links</b> between   nodes.   Hypothesis evaluation is treated as the satisfaction of <b>constraints</b>     determined from the explanatory relations (that is, explanations and/or contradictions), TEC's   principles, and from a few <b>numerical parameters</b>. Given a network of statements and  relations between them, node activations are updated in parallel using a simple  "<b>connectionist</b>" settling scheme.   When the network of statements settles (or   stabilizes), the nodes representing the most mutually coherent hypotheses and evidence   are active, and the nodes representing inconsistent rivals are deactivated.  </p><p>For example, suppose Chris says:</p><p class="example">Some people think that all animals (including humans) were created in   their present form, about 5000 years ago. Others believe that animals evolved from earlier   life slowly, over millions of years.   Both beliefs explain why animals exist. However,   only the latter, evolutionary, hypothesis explains why transitions between forms in the   fossil records appear to be gradual, and why scientists have found some fossils they   estimate are over a million years old. </p><p>This could be represented in ECHO as: </p><p class=example>Hypothesis H1: Animals were created in their present form about 5000 years ago. </p><p class=example>Hypothesis H2: Animals evolved from earlier life over millions of years. </p><p class=example>Evidence E1: Animals exist. </p><p class=example>evidence E2: Transistions between forms in the fossil records are gradual. </p><p class=example>evidence E3: Scientists have dated some fossils at over a million years old. </p><p class=example>H1 competes with H2 </p><p class=example>H1 explains E1 </p><p class=example>H2 explains E1 </p><p class=example>H2 explains E2 </p><p class=example>H2 explains E3 </p><p>Or, in graphical network form (where solid lines represent explanatory links, and the dashed   line represents a competing/contradictory link): </p><br><p align=center><img width=163 height=66 src="network.gif"></p><br><p>Given a scenario such as this, ECHO generates a numerical value for each statement  that indicates how much it believes the statement.   In general, the more positive the value,   the more ECHO "believes" the statement; the more negative the value, the more ECHO "disbelieves"   the statement. In this case, ECHO believes H2 over H1 since H2 explains more of the evidence.  </p><h2>Entering an argument</h2><p> The <b>File</b> menu lets you create a new argument, load an existing argument, or save   your argument (see Figure 2).</p>  <br><p align=center><img width=207 height=188 src="filemenu.jpg"></p><p align=center><b>Figure 2</b>. The <b>File</b> menu. </p><br><p align=center><img width=503 height=211 src="textwindow.gif" </p><p align=center><b>Figure 3</b>. Text window with <b>Hypotheses</b> and<b>Data</b>  fields, with part of the"Ice Cubes" argument we saw earlier. </p> <br><p>When you want to enter statements for your argument, click the <b>hypothesis</b>  or <b>evidence</b>  button at the top of the Convince Me  screen (see Figure 3).  A  dialog box will then ask you what statement you would like to add (see Figure 4).    It will also ask you to check one or more boxes (you may check no boxes if none really  apply) and how believable the statement is to you. If the statement is a piece of evidence,   Convince Me also wants to know how reliable you think it is. </p><br><p align=center ><img width=437 height=436 src="editprop.gif" ></p><p align=center><b>Figure 4</b>. Dialog box to add or edit a statement of evidence. </p><br><p> Each statement that you add is represented by an icon in the <b>Diagram</b> window.   As you enter your propositions, a round yellow icon appears for every hypothesis,  and a square green icon appears for every piece of evidence (see Figure 5).  The label   for the proposition is below the icon, and if you pass the mouse arrow over an icon,   the text of the statement that it represents will show up under the diagram. </p><br><p align=center><img width=500 height=500 src="diagramwindow.gif"></p><p align=center><b>Figure 5</b>. Statement icons in the Diagram window and   text of proposition E2 below the diagram. </p><br><p>If you want to change the text of a statement, or reclassify it as hypothesis or   evidence or vice versa, go back to the <b>Text</b> window, click on the statement   you want to modify in the <b>Hypothesis</b> field, then select <b>Edit Selected   Propositions</b> from the <b>Edit</b>  menu (see Figure 6). If you want to delete a   statement, select the statement and then click <b>Delete Selected</b> from the   <b>Edit</b> menu. After you've entered some statements, you can specify some explanations   and contradictions among them. </p><br><p align=center><img width=498 height=289 src="editmenu.gif"></p><p align=center><b>Figure 6.</b>  Editing a selected proposition from the Text   window.</p><br>  <h3>Exercise 1</h3><p>Create a new argument by selecting <b>New Argument</b> from the <b>File</b> menu.    Add the following hypotheses and evidence to your argument (from the "Ice Cubes" argument   in Unit 2).  Don't specify any explanations and contradictions yet. </p><p>Hypotheses: </p><p class=example>To make ice cubes freeze faster, use hot water, not cold water (H1).</p><p class=example>To make ice cubes freeze faster, use cold water, not hot water (H2).</p><p class=example>Water in the freezer should behave the same way as objects cooling to room temperature (H3).</p><p>Evidence:</p><p class=example>The hotter something is, the longer it takes it to cool to room temperature (E1).</p><p class=example>Latisha's Mom mfound that hot water did freeze faster (E2).</p><h2>Adding and deleting explanations</h2><p>To create an explanation, click on the <b>explain</b> button. A dialog box will appear   with a list of statements, and ask you to specify your explanation (see Figure 7). You   can select multiple statements by holding down the shift key when you click on a statement.   If you select multiple statements in the top field, the computer will interpret these statements  as <i>jointly</i> explaining them statement in the bottom field (e.g., Todd singing and Mary   singing jointly explains why it sounded like a duet). Your explanation will then appear in the   explanations field (see Figure 8) and in the Diagram window. </p><p> To delete an explanation, select the explanation in the Text window and then click <b>Delete  Selected</b> from the <b>Edit</b> menu. </p><br><p align=center><img width=491 height=480 src="addexplain.gif"></p><p align=center><b>Figure 7</b>. Dialog box for adding an explanation. </p><br><p align=center><img width=485 height=65 src="explanations.jpg"></p><p align=center><b>Figure 8</b>. <b>Explanations</b> field after the first addition from Exercise 2. </p><br><h3>Exercise 2</h3><p>Add the following explanations to your ice cubes argument.</p><p class=example>E1 and H3 jointly explain H2</p><p class=example>H1 explains E2</p><h2>Adding and deleting contradictions</h2><p>To specify a contradiction, click on the <b>contradict</b> button. A dialog box will   appear with a list of statements, and ask you to specify your contradiction. Select one   statement from each list (see Figure 9). Your contradiction will then appear in the   contradiction field and in the Diagram window. </p><p> To delete a contradiction, select the contradiction in the Text window and then click   <b>Delete Selected</b> from the <b>Edit</b> menu. </p><br><p align=center><img width=487 height=436 src="addcontradiction.gif"></p><p align=center> <b>Figure 9</b>. Dialog box for adding a contradiction. </p><br><h3>Exercise 3</h3><p>Add the following contradiction to your ice cubes argument. </p><p class=example>H1 contradicts H2 </p><h2>Rearranging the diagram of your argument</h2><p>Convince Me will draw a diagram of your argument in the <b>Diagram</b> window. You can   rearrange the diagram so that it makes sense to you (see Figures 10 and 11). You can move   the icons by clicking on them with the mouse pointer and slowly dragging them across the   screen while holding down the mouse button. The explanatory links you have entered will be   drawn with solid lines and the contradictory links will be drawn with dotted lines. </p><br><p align=center><img width=440 height=255 src="icecubesunarranged.gif"></p><p align=center><b>Figure 10</b>. Diagram window for Ice Cubes argument with original   arrangement of icons.</p><br><p align=center><img width=440 height=268 src="icecubesarranged.gif"></p><p  align=center><b>Figure 11</b>. Diagram window for Ice Cubes argument with icons   rearranged to form a more meaningful diagrammatic representation of the argument. </p><br><p>Sometimes an explanation or contradiction link (solid or dotted line), or even a proposition   icon, on the diagram may be hidden due to the positioning of the proposition icons. If you   add an explanation, contradiction, or statement and you notice that it does not appear on   the diagram, rearrange the icons so that all the links and icons are displayed. </p><h3>Exercise 4</h3><p> Arrange the icons for the "Ice Cubes" argument as pictured in Figure 11. </p><h3>Exercise 5</h3><p>The diagram that you just built is arranged such that the propositions that explain something   else are positioned <i>above</i> the propositions they are explaining. Also, the propositions   supporting a single hypothesis are positioned nearby, whereas propositions supporting more  than one hypothesis could be positioned centrally. Does this seem to be a good way to view   the argument? What other features of the diagram may help you to “see” the argument better?   Feel free to rearrange the diagram so that it represents the argument in a form meaningful to you. </p><h2>Ok, I've entered my argument.</h2><p>Now you can run the simulation and see what the computer thinks.  But first, you should  rate how strongly you believe each of the statements you entered, so you have something to compare   with the computer's evaluations.  If you did not rate the believability of each statement as  you entered it, do that now. Click on a statement that you want to rate and then click on    <b>Edit Selected Propositions</b> from the <b>Edit</b> menu. Then enter your rating, on a scale from 1   (low, completely disbelieved), to 9 (high, completely believed), where 5 is "neutral” (see Figure 12). </p><br><p align=center><img width=360 height=125 src="believability.jpg"></p><p align=center><b>Figure 12</b>. Entering a believability rating. </p><br><h3>Exercise 6</h3><p>Enter your believability ratings for the statements in the "Ice Cubes" argument, if you did   not already do so when you created the statements. </p><h2>Running the Simulation</h2><p>To get an idea of the overall agreement between your ratings and ECHO's, you can run the   ECHO model. To do so, go to the <b>Simulation</b>  menu and select <b>Run</b> (see Figure 13).     ECHO will then compute a <em>correlation</em> between your ratings and ECHO's activations   (see Figure 14). The possible range for the correlation is -1 to 1.</p><br><p align=center><img width=184 height=67 src="simulationmenu.jpg"></p><p align=center><b>Figure 13.</b> Use the Simulation  menu to run the model. </p><br><p align=center><img width=330 height=125 src="correlation.jpg"></p><p align=center><b>Figure 14.</b> How your ratings compare to ECHO's activations, overall.</p><br><h3>Exercise 7</h3><p>Run a simulation for your argument (choose <b>Run</b> from the <b>Simulation</b>  menu). </p><h2>How do I compare my ratings to ECHO's activations?</h2><p>You can compare your ratings with ECHO's in two ways. The higher the overall correlation,   the more ECHO agrees with your ratings--based on your argument. (A negative correlation means   that your ratings are actually <i>disagreeing</i>  with ECHO's activations.) Table 1 shows   the ranges of correlation values used to determine how related your ratings are to ECHO's   activations overall. </p><p>In addition, in the Text window, you can see your individual ratings as well as ECHO’s   individual activations, and see how they agree and disagree (see Figure 15). </p><p align=center>Table 1</b>. Determining the overall agreement between your evaluations and ECHO's. </p><center><table border="1" cellspacing="0" cellpadding="5"> <tr>  <td><b>Correlation Range</b></td>  <td><b>Relation between your evaluations and ECHO's</b></td> </tr> <tr>  <td>-0.99 up to -0.40 </p></td>  <td>Mostly opposite</td> </tr> <tr>  <td>-0.40 up to -0.01</td>  <td>Mildly opposed</td> </tr> <tr>  <td>0.0</p></td>  <td>Unrelated</td> </tr> <tr>  <td>0.01 up to 0.40</td>  <td>Mildly related</td> </tr> <tr>  <td>0.40 up to 0.70</td>  <td>Moderately related</td> </tr> <tr>  <td>0.70 up to 0.90</td>  <td>Highly related</td> </tr> <tr>  <td>0.90 up to 0.99</td>  <td>Almost identical</td> </tr></table></center><br><br><p align=center><img src="compareratings.gif"></p><p align=center><b>Figure 15</b>. Comparing your individual ratings with ECHO's individual  activations.</p><br><h3>Exercise 8</h3><p>How do your believability ratings compare to ECHO's? For what statements do your and ECHO's   ratings differ the most? For which statements are they the most similar? How well do your ratings  agree with ECHO's overall? If you and ECHO didn't correlate as well as you thought you would, why   might that be?</p><h2>What if ECHO and I don't agree?</h2><p> If you don't "convince" Convince Me  the first time, that is, if ECHO doesn't agree with   your evaluations, there are a few things you can try. For instance, look at the structure of  your argument:  Do you want to change it?  Did you leave some explanations or contradictions out?   Should some independent explanations be a joint explanation or vice versa? Look at your   statements: Do you want to add or delete some? Do you want to change some of your ratings?    (Don't say that you believe something if you don't, just because ECHO "believes" it!) </p><p>You could even try changing some of ECHO's numerical parameter settings to make ECHO better   model your way of thinking. If you want to change the parameters, select <b>Set Parameters...</b>  in the  <b>Simulation</b> menu.  A <b>Parameters</b>  window will appear (see Figure 16). If   you change the parameters and then want to reset them to the original values, click on the    <b>Use Default</b> button in the <b>Parameters</b> window. </p><br><p align=center><img width=437 height=486 src="parameters.gif"></p><p align=center><b>Figure 16</b>. Parameters window. </p><br><p>For example, if you think ECHO is being too "tolerant" compared to you, you might lower   the <b>Excitation (explanation) weight</b> and/or raise the <b>Inhibition (contradiction)  weight</b>. If you think ECHO is not "tolerant" enough, you could raise the <b>Excitation   weight</b> and/or lower the <b>Inhibition weight</b>.  If you think ECHO isn't giving the   proper weight to evidence, you could lower or raise the <b>Data Priority</b>. If you think   ECHO is being too "skeptical," you could lower the <b>Skepticism </b> weight. If ECHO is   not as skeptical as you, you might raise <b>Skepticism</b>.</p><p>It is possible that you may look at all of these things, make some changes, re-run the   simulation, and ECHO still won't agree with you like you thought it would. That's okay,   sometimes you just can't convince everyone, no matter how hard you try!  But the important  thing is that you think about your argument, reflect on it, and think about your own reasoning   strategies.  </p><h3>Exercise 9</h3><p>Implement at least one change to your ice cubes argument. Feel free to add, delete, or modify   whatever statements, explanations, or contradictions that seem appropriate. (For example,  you might add the information that since more of the hot water evaporates, there is less water   to freeze, so it takes less time to freeze than the eventually-more-massive cold water.)   Rearrange the diagram to reflect your changes to the argument. </p><h3>Exercise 10</h3><p>Create an argument in Convince Me based on the "Rats" text from Unit 2 (the argument is   reproduced below).   Run an ECHO simulation of your argument, and based on ECHO's feedback,   make at least one change to your argument. Feel free to add, delete, or modify whatever   statements, explanations, or contradictions that seem appropriate.  </p><p class=example>A UC Berkeley researcher believed that interesting, educational experiences   in early life lead to larger brains. She found that rats raised alone in the empty  cages had smaller brains than the rats raised together &nbsp;  in the interesting  environment. Based on this experiment, she concluded that children who have interesting,   educational experiences in preschools will< grow up to be more intelligent adults  than children who do not attend preschool. </p><p class=example>A preschool teacher disagreed with the researcher. She said that the rat   experiment could not be used to explain the advantages of attending preschool.</p><p> That's all for Unit 3!  You may want to read through the summary <a href="#glossary">Glossary   of terms</a>, and see the <a href="#appendix">Appendix</a> to learn more about how Convince Me  evaluates your arguments. </p><a name="glossary"></a><h2>Glossary</h2><p><b>Argument</b>: A system of beliefs that is generally more complex than one explanation/   contradiction, but less than that of a theory. </p><p><b>Belief</b>: A hypothesis or piece of evidence. </p><p><b>Believabilty rating</b>  : Given a proposition, how strongly it is believed. </p><p><b>Confirmation bias:</b>  When one seeks to support certain arguments/beliefs in a biased   fashion, with out trying to disconfirm them. </p><p><b>Contradiction/Conflict:</b> The relation between a pair of beliefs that are mutually   exclusive or (at least) unlikely to both be true.  </p><p><b>Disconfirmation:</b> When one attempts to garner evidence that contradicts a (even  favorite) theory. </p><p><b>Evidence</b>:  A belief that seems based on "objective-like" criteria; for example, an  acknowledged common fact or statistic, or a reliable memory or observation.  </p><p><b>Explanation</b>: Something that shows how or why something happened. The coordination   of beliefs such that some are accounted for (often causally) by others. </p><p><b>Hypothesis</b>: One possible belief that explain/tells something of interest. </p><p><b>Joint Explanation</b>: An explanation in which two or more beliefs together (vs.   independently) explain a third belief. </p><p><b>Primacy bias:</b> A tendency to give too much credence to early information.</p><p><b>Recency bias:</b> A tendency to give too much credence to recent information.</p><p><b>Theory</b>: A system of evidential and hypothetical beliefs that have a unifying theme.  </p><a name="appendix"></a><h2>Appendix: Some Principles That Underly TEC and ECHO</h2><p><b>Symmetry</b>: "Coherence and incoherence are symmetric relations." This means that   if one belief explains (or conflicts with) another, the beliefs "send activation" back   and forth to each other. (E.g., If I'm playing cards with you, then you're playing cards   with me. If I'm not playing with you, then you're not playing with me.) </p><p><b>Explanation</b>: "A belief that explains a proposition coheres with it.   Also, beliefs  that jointly explain a proposition cohere with it, and cohere with each other." Two or   more beliefs that together explain a third belief are generally called "cohypotheses" if   they are both hypotheses (or sometimes "cobeliefs" if one or more is evidence).   According   to this principle, for example, cohypotheses "send activation" to each other, as well as to   the explained belief. (E.g.,   Todd singing and Mary singing jointly explains why it sounded   like a duet, and send activation to "duet", as well as to each other.) </p><p><b>Simplicity</b>: "The plausibility of a proposition is inversely related to the number of   explaining statements needed to explain it."  The simpler the explanation, the more likely it   will be believed. That is, lots of assumptions (or co-beliefs) are often counterproductive,   compared to fewer assumptions. </p><p><b>Data Priority</b>: "Results of observations have an extra measure (boost) of acceptability."   This means that acknowledged facts, memories, and observations carry more importance than "mere"  hypotheses. </p><p><b>Contradiction</b>: "Contradictory hypotheses incohere." This means that beliefs that conflict  with each other send "negative activation" (or "inhibition") to each other, like rival members  of two different "gangs." </p><p><b>Competition</b>: "Competing beliefs (which explain the same evidence or hypotheses but are   not themselves explanatorily related) incohere."   This means that highly independent explainers   of the same proposition conflict with each other, and hence send "negative activation" to each   other, like rival gang members vying for the same turf. (E.g., If you hear a report that an evil   dictator was shot, and later hear that he was stabbed, you might assume that the two reports offer   competing hypotheses.) This principle may be optionally invoked in a variant of ECHO, called ECHO2,   which automatically infers inhibitory relationships between propositions that independently   (not <i>jointly</i>) explain a third proposition. </p><p><b>Acceptability</b>: "The acceptability of a proposition increases as it coheres more with   other acceptable propositions, and <i>in</i>coheres more with <i>un</i>acceptable propositions."    This basically says that how much a belief is believed is a function of who its friends and  enemies are, and how much <i>they</i>  are believed. </p><p><b>Overall Coherence</b>: "The overall coherence of a network of propositions depends on the   local pairwise cohering of its propositions." This basically means that the goodness of a  whole "neighborhood system" of beliefs is determined by the believability of its members and  their relationships.  </p></body></html>